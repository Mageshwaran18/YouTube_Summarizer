# YouTube_Summarizer

Step 1 : Download the [Ollama](https://ollama.com/download/windows)
<br>
Step 2 : To see the LLM supported by the Ollama 
```ollama list```
<br>
Step 3 : To install and run the LLama3 
```ollama run llama3```
<br>
Step 4 : ```ollama serve``` can be used to run the server
<br>
Step 5 : To create an customized model , create Model_File. This enables you to transfer the custom model from one system to the another
<br>
Step 6 : The run create the customized model using ```ollama create Model_Name -f ./Module_File```
<br>
